{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#NLP - Introduction & Text Processing\n",
        "                             SUBMITTED BY: MD FAHAM NAUSHAD"
      ],
      "metadata": {
        "id": "xe7L-eaWFuNw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***************************************************\n",
        "##Question\n",
        "\n",
        "#***************************************************"
      ],
      "metadata": {
        "id": "VYnvKepCQPi1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 1: What is Computational Linguistics and how does it relate to NLP?\n",
        "\n",
        "- Answer:\n",
        "\n",
        "  Computational Linguistics is the scientific study of language using computational models. It focuses on how machines can understand and generate human language similar to humans. Natural Language Processing (NLP) applies computational linguistics to real-world tasks like translation, chatbots, sentiment analysis, etc. So NLP is the applied form of computational linguistics used to build human–machine language interaction systems.\n",
        "\n",
        "##Question 2: Briefly describe the historical evolution of Natural Language Processing.\n",
        "\n",
        "- Answer:\n",
        "\n",
        "  NLP started in the 1950s with simple rule-based translation systems. In the 1980s–1990s, statistical models became popular due to the availability of digital text. After 2010, deep learning and neural networks revolutionized NLP and improved language understanding drastically. Today, NLP uses transformer-based models like BERT and GPT, which provide near human-level performance on many tasks.\n",
        "\n",
        "##Question 3: List and explain three major use cases of NLP in today’s tech industry.\n",
        "\n",
        "- Answer:\n",
        "\n",
        "  \n",
        "- 1️⃣ Chatbots & Virtual Assistants:\n",
        "\n",
        "    - NLP enables chatbots and voice assistants like Siri, Alexa, and Google Assistant to understand natural human language. It analyses the user’s message, identifies intent (what the user wants), and generates a suitable response. Modern systems also learn user preferences over time to give more personalized replies. Many companies now use NLP chatbots for 24×7 customer support, reducing response time and operating cost.\n",
        "\n",
        "- 2️⃣ Sentiment Analysis:\n",
        "\n",
        "    - Sentiment analysis helps businesses understand people’s emotions from written text such as product reviews, social media comments, and surveys. NLP models classify the tone of a message as positive, negative, or neutral, allowing companies to measure satisfaction and detect problems early. It is heavily used in brand monitoring, market research, and feedback analysis to support decision-making and marketing strategies.\n",
        "\n",
        "- 3️⃣ Machine Translation:\n",
        "\n",
        "    - Machine translation automatically converts text from one language to another (e.g., English → Hindi). Traditional translation systems relied on manually created dictionaries and grammar rules, but now NLP-based deep learning systems (like Google Translate) understand context rather than just word mappings. Modern translation models handle slang, culture-specific expressions, and sentence structure, making global communication easier for business, education, and tourism.\n",
        "\n",
        "\n",
        "      | Use Case            | What NLP Does             | Real-World Example                 |\n",
        "      | ------------------- | ------------------------- | ---------------------------------- |\n",
        "      | Chatbots            | Understand intent & reply | Amazon Alexa, Bank support bots    |\n",
        "      | Sentiment Analysis  | Detect human emotions     | Review analysis on Flipkart/Amazon |\n",
        "      | Machine Translation | Convert languages         | Google Translate, subtitles        |\n",
        "\n",
        "\n",
        "##Question 4: What is text normalization and why is it essential in text processing tasks?\n",
        "\n",
        "- Answer:\n",
        "\n",
        "  Text normalization converts raw text into a clean, standard form that a model can understand. It includes removing punctuation, converting to lowercase, expanding contractions, and fixing spelling. It reduces variations in text so the algorithm focuses on meaning instead of formatting differences. Without normalization, models treat similar words differently and performance decreases.\n",
        "\n",
        "##Question 5: Compare and contrast stemming and lemmatization with suitable examples.\n",
        "\n",
        "- Answer:\n",
        "\n",
        "  Stemming cuts off the ends of words to reduce them to their base form (e.g., playing → play, studies → studi). It is fast but sometimes produces non-dictionary words. Lemmatization converts words to their root dictionary form using grammar rules (e.g., studies → study, better → good). It is slower but more meaningful and accurate. Both aim to reduce word variation.\n",
        "\n",
        "##Question 6: Write a Python program that uses regular expressions (regex) to extract all email addresses from the following block of text:\n",
        "- “Hello team, please contact us at support@xyz.com for technical issues, or reach out to our HR at hr@xyz.com. You can also connect with John at john.doe@xyz.org and jenny via jenny_clarke126@mail.co.us. For partnership inquiries, email partners@xyz.biz.”\n",
        "\n",
        "\n",
        "###Answer:\n",
        "\n",
        "✅Python Code:"
      ],
      "metadata": {
        "id": "uEwpiaZTQTj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "text = \"\"\"Hello team, please contact us at support@xyz.com for technical issues, or reach out to our HR at hr@xyz.com.\n",
        "You can also connect with John at john.doe@xyz.org and jenny via jenny_clarke126@mail.co.us.\n",
        "For partnership inquiries, email partners@xyz.biz.\"\"\"\n",
        "\n",
        "emails = re.findall(r'\\b[\\w\\.-]+@[\\w\\.-]+\\.\\w+\\b', text)\n",
        "print(emails)\n"
      ],
      "metadata": {
        "id": "hSduR-RVGAhg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "366dca46-a078-472d-e2aa-a903183f14e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['support@xyz.com', 'hr@xyz.com', 'john.doe@xyz.org', 'jenny_clarke126@mail.co.us', 'partners@xyz.biz']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4S4HLoy3WMFO",
        "outputId": "5dec2847-8f30-4ca8-ae8a-b888dd05a063"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 7: Given the sample paragraph below, perform string tokenization and frequency distribution using Python and NLTK:\n",
        "\n",
        "  - “Natural Language Processing (NLP) is a fascinating field that combines linguistics, computer science, and artificial intelligence. It enables machines to understand, interpret, and generate human language. Applications of NLP include chatbots, sentiment analysis, and machine translation. As technology advances, the role of NLP in modern solutions is becoming increasingly critical.”\n",
        "\n",
        "\n",
        "###Answer:\n",
        "\n",
        "✅Python Code:"
      ],
      "metadata": {
        "id": "NRelvgQuS9xi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "\n",
        "paragraph = \"\"\"Natural Language Processing (NLP) is a fascinating field that combines linguistics, computer science,\n",
        "and artificial intelligence. It enables machines to understand, interpret, and generate human language. Applications of NLP\n",
        "include chatbots, sentiment analysis, and machine translation. As technology advances, the role of NLP in modern solutions\n",
        "is becoming increasingly critical.\"\"\"\n",
        "\n",
        "tokens = word_tokenize(paragraph.lower())\n",
        "fd = FreqDist(tokens)\n",
        "\n",
        "print(\"Top 10 most common words:\")\n",
        "print(fd.most_common(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zK0A8HRjQKz2",
        "outputId": "b39477f1-56a1-4e03-8d0c-8fc2697b278e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 most common words:\n",
            "[(',', 7), ('.', 4), ('nlp', 3), ('and', 3), ('language', 2), ('is', 2), ('of', 2), ('natural', 1), ('processing', 1), ('(', 1)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 8: Create a custom annotator using spaCy or NLTK that identifies and labels proper nouns in a given text.\n",
        "\n",
        "\n",
        "###Answer:\n",
        "\n",
        "✅Python Code:"
      ],
      "metadata": {
        "id": "SwnSj-UmTIqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "text = \"Steve Jobs founded Apple in California and later introduced the iPhone.\"\n",
        "\n",
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    if token.pos_ == \"PROPN\":\n",
        "        print(token.text, \"→ Proper Noun\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BMohys6TL-c",
        "outputId": "8a38917b-0fcb-4d63-8a3a-36dfb7a97a8a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steve → Proper Noun\n",
            "Jobs → Proper Noun\n",
            "Apple → Proper Noun\n",
            "California → Proper Noun\n",
            "iPhone → Proper Noun\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 9: Using Genism, demonstrate how to train a simple Word2Vec model on the following datase:\n",
        "\n",
        "    dataset = [\n",
        "    \"Natural language processing enables computers to understand human language\",\n",
        "    \"Word embeddings are a type of word representation that allows words with similar\n",
        "    meaning to have similar representation\",\n",
        "    \"Word2Vec is a popular word embedding technique used in many NLP applications\",\n",
        "    \"Text preprocessing is a critical step before training word embeddings\",\n",
        "    \"Tokenization and normalization help clean raw text for modeling\"\n",
        "    ]\n",
        "\n",
        "Write code that tokenizes the dataset, preprocesses it, and trains a Word2Vec model using Gensim.\n",
        "\n",
        "###Answer:\n",
        "✅Python Code:"
      ],
      "metadata": {
        "id": "gHZ4lvPSTdwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiZNpedFWsfj",
        "outputId": "f9b837fc-ebb7-4c5f-811e-bbeb4af454c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import nltk\n",
        "\n",
        "dataset = [\n",
        " \"Natural language processing enables computers to understand human language\",\n",
        " \"Word embeddings are a type of word representation that allows words with similar meaning to have similar representation\",\n",
        " \"Word2Vec is a popular word embedding technique used in many NLP applications\",\n",
        " \"Text preprocessing is a critical step before training word embeddings\",\n",
        " \"Tokenization and normalization help clean raw text for modeling\"\n",
        "]\n",
        "\n",
        "sentences = [nltk.word_tokenize(sent.lower()) for sent in dataset]\n",
        "model = Word2Vec(sentences, vector_size=50, window=3, min_count=1, workers=4)\n",
        "\n",
        "word = \"language\"\n",
        "print(\"Closest words to 'language':\")\n",
        "print(model.wv.most_similar(word, topn=5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Psu-9I64TgkT",
        "outputId": "275ddd57-dc61-4520-de72-b85b6344773a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Closest words to 'language':\n",
            "[('used', 0.3151129484176636), ('for', 0.2373713254928589), ('meaning', 0.2184678167104721), ('of', 0.20302735269069672), ('to', 0.1844237893819809)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question 10: Imagine you are a data scientist at a fintech startup. You’ve been tasked with analyzing customer feedback. Outline the steps you would take to clean, process, and extract useful insights using NLP techniques from thousands of customer reviews.\n",
        "\n",
        "  - (Include your Python code and output in the code box below.)\n",
        "###Answer:\n",
        "- Explanation:\n",
        "  \n",
        "  To analyze thousands of customer reviews, I would first clean the text using normalization, tokenization, stopword removal, and lemmatization. Then I would convert text into numeric form using TF-IDF or Word2Vec embeddings. Next, I would apply models like sentiment analysis or topic modeling to extract insights such as common complaints and satisfaction scores. Finally, I would visualize results in dashboards to support business decision-making.\n",
        "\n",
        "✅Python Code:"
      ],
      "metadata": {
        "id": "p-Fsy-lNdaCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install textblob\n",
        "\n",
        "from textblob import TextBlob\n",
        "\n",
        "reviews = [\n",
        "    \"The loan approval process was smooth and fast!\",\n",
        "    \"Customer support never responds. Very disappointing.\",\n",
        "    \"I love the app. It is easy to use and secure.\",\n",
        "    \"The transaction failed twice and I lost money.\"\n",
        "]\n",
        "\n",
        "for r in reviews:\n",
        "    score = TextBlob(r).sentiment.polarity\n",
        "    sentiment = \"Positive\" if score > 0 else \"Negative\" if score < 0 else \"Neutral\"\n",
        "    print(f\"{r} → {sentiment} (score = {score})\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "efLQlbsKdadE",
        "outputId": "97032353-f988-4744-b0e1-a31252303ca6"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.12/dist-packages (0.19.0)\n",
            "Requirement already satisfied: nltk>=3.9 in /usr/local/lib/python3.12/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (1.5.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk>=3.9->textblob) (4.67.1)\n",
            "The loan approval process was smooth and fast! → Positive (score = 0.325)\n",
            "Customer support never responds. Very disappointing. → Negative (score = -0.78)\n",
            "I love the app. It is easy to use and secure. → Positive (score = 0.4444444444444445)\n",
            "The transaction failed twice and I lost money. → Negative (score = -0.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###************** END  **************"
      ],
      "metadata": {
        "id": "74lX2k1WOFhu"
      }
    }
  ]
}